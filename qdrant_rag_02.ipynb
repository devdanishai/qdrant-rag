{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd41cde8331b4da8a564fb175961cd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd1bc3878fd04dbe9b366b28b8e8cef3",
              "IPY_MODEL_2d5e496f78be4a8e87eb2184a4cfc5ab",
              "IPY_MODEL_0909d666d6b14e0081d69055dd7d01f3"
            ],
            "layout": "IPY_MODEL_f7c0f3aea0124ab2b4427fc281cc49da"
          }
        },
        "cd1bc3878fd04dbe9b366b28b8e8cef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d71485cc72471baad7e23a6dd4ed07",
            "placeholder": "​",
            "style": "IPY_MODEL_30e28c6c189e4b41af564fd0ba389d8f",
            "value": "Downloading data: 100%"
          }
        },
        "2d5e496f78be4a8e87eb2184a4cfc5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0b199e50434b209d11f3fd87d00fbb",
            "max": 152907501,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e39f86567f4b4f7ba29703299ce48e15",
            "value": 152907501
          }
        },
        "0909d666d6b14e0081d69055dd7d01f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0681d4966c704f56b9896ba150a0464a",
            "placeholder": "​",
            "style": "IPY_MODEL_b67ea910dc8e45daaeb266c7c74629c1",
            "value": " 153M/153M [00:01&lt;00:00, 175MB/s]"
          }
        },
        "f7c0f3aea0124ab2b4427fc281cc49da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d71485cc72471baad7e23a6dd4ed07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e28c6c189e4b41af564fd0ba389d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0b199e50434b209d11f3fd87d00fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39f86567f4b4f7ba29703299ce48e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0681d4966c704f56b9896ba150a0464a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67ea910dc8e45daaeb266c7c74629c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8d9afd7a71f4ab2b49c2826b9d93328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47f9179b163648d4980fb7e2933c815c",
              "IPY_MODEL_1fd82cb66f7447beadb914b9b4601a81",
              "IPY_MODEL_ee3ce872a1f04044bf92d3f4ede07156"
            ],
            "layout": "IPY_MODEL_29cceb6785474dc192c408901df97300"
          }
        },
        "47f9179b163648d4980fb7e2933c815c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3482d47c174f5d8fc1a8d345d8d1f9",
            "placeholder": "​",
            "style": "IPY_MODEL_0aedeebc6f26469891e5820d61e5a099",
            "value": "Generating train split: 100%"
          }
        },
        "1fd82cb66f7447beadb914b9b4601a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e542a2395e464c40a4e22c6d865e0609",
            "max": 41584,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e66e7d8a711d45f9a1830dcbcdddff67",
            "value": 41584
          }
        },
        "ee3ce872a1f04044bf92d3f4ede07156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2006fb8c374ee883d04eee48ead8be",
            "placeholder": "​",
            "style": "IPY_MODEL_dabbce0532c8449c9d058674c33d4f3f",
            "value": " 41584/41584 [00:01&lt;00:00, 23077.28 examples/s]"
          }
        },
        "29cceb6785474dc192c408901df97300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3482d47c174f5d8fc1a8d345d8d1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aedeebc6f26469891e5820d61e5a099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e542a2395e464c40a4e22c6d865e0609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66e7d8a711d45f9a1830dcbcdddff67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af2006fb8c374ee883d04eee48ead8be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dabbce0532c8449c9d058674c33d4f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "17/dec/2024\n",
        "this is notebook i create\n",
        "\n",
        "1.   create token with openai text-embedding-3-large\n",
        "2.   download dataset\n",
        "3.   create collection\n",
        "4.   add data to collection\n",
        "\n"
      ],
      "metadata": {
        "id": "BSe8a6h8HP0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv==1.0.1 qdrant-client==1.9.0 openai==0.28 transformers==4.40.1 sentence-transformers==2.7.0 datasets==2.19.0"
      ],
      "metadata": {
        "id": "cJlXQCH9DtPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d262c208-799a-4633-c5c0-045065f834e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv==1.0.1\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting qdrant-client==1.9.0\n",
            "  Downloading qdrant_client-1.9.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers==4.40.1\n",
            "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers==2.7.0\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting datasets==2.19.0\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client==1.9.0) (1.68.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client==1.9.0)\n",
            "  Downloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client==1.9.0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client==1.9.0) (1.26.4)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client==1.9.0)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client==1.9.0) (2.10.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client==1.9.0) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.1) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.1) (0.26.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.1) (2024.9.11)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.1)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.1) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (11.0.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0) (17.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.19.0)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.19.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0) (2.2.2)\n",
            "Collecting xxhash (from datasets==2.19.0)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.19.0)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.0)\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client==1.9.0)\n",
            "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client==1.9.0) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.9.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.9.0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.9.0) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.9.0) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.9.0) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client==1.9.0)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client==1.9.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client==1.9.0) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers==2.7.0) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.19.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.7.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.7.0) (3.5.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client==1.9.0)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client==1.9.0)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.0) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.9.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.9.0) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.7.0) (3.0.2)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading qdrant_client-1.9.0-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: xxhash, python-dotenv, pyarrow-hotfix, protobuf, portalocker, hyperframe, hpack, fsspec, dill, multiprocess, h2, grpcio-tools, tokenizers, transformers, qdrant-client, openai, sentence-transformers, datasets\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.2.1\n",
            "    Uninstalling sentence-transformers-3.2.1:\n",
            "      Successfully uninstalled sentence-transformers-3.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.3.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.19.0 dill-0.3.8 fsspec-2024.3.1 grpcio-tools-1.68.1 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 multiprocess-0.70.16 openai-0.28.0 portalocker-2.10.1 protobuf-5.29.1 pyarrow-hotfix-0.6 python-dotenv-1.0.1 qdrant-client-1.9.0 sentence-transformers-2.7.0 tokenizers-0.19.1 transformers-4.40.1 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p45WXlYseAge",
        "outputId": "dcdbf0cf-a1a7-483d-eb29-d504cc4f155f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken==0.6.0\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.6.0) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.6.0) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.6.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.6.0) (2024.8.30)\n",
            "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "wZMmnvjrjhL4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"def hello_world(): print('Hello, world! 🌍') # Bonjour, 世界! Hola, mundo! 1 + 1 = 2, π ≈ 3.14159, e^(i*π) + 1 = 0.\"\n"
      ],
      "metadata": {
        "id": "OBsiyNu8jmXA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(example_text.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LigRNHNkTAg",
        "outputId": "f63dd544-4b05-4006-fa4b-8b1151f099c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of tokens\n",
        "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
        "    \"\"\"\n",
        "    Calculate the number of tokens in a given text string using a specified encoding.\n",
        "\n",
        "    Args:\n",
        "        string (str): The input text string to be tokenized.\n",
        "        encoding_name (str, optional): The name of the encoding to use for tokenization.\n",
        "            Defaults to \"cl100k_base\". Other supported encodings include \"p50k_base\",\n",
        "            \"p50k_edit\", \"r50k_base\", etc.\n",
        "\n",
        "    Returns:\n",
        "        int: The number of tokens in the input text string.\n",
        "\n",
        "    Note:\n",
        "        The number of tokens returned by this function depends on the chosen encoding.\n",
        "        Different encodings may have different tokenization rules and vocabulary sizes.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If an invalid encoding name is provided.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        encoding = tiktoken.get_encoding(encoding_name)\n",
        "        num_tokens = len(encoding.encode(string))\n",
        "        return num_tokens\n",
        "    except KeyError:\n",
        "        raise ValueError(f\"Unsupported encoding: {encoding_name}\")\n",
        "\n",
        "num_tokens_from_string(example_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6_V7mAlkVPQ",
        "outputId": "86baaff3-ce1f-4b58-84aa-bde683697bc2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text, token, and integer representation of each token in the string.\n",
        "def from_text_to_tokens(text:str, encoding_name: str =  \"cl100k_base\" ):\n",
        "    \"\"\"\n",
        "    Tokenize the given text using the cl100k_base encoding.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be tokenized.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    tokens = encoding.encode(text)\n",
        "    subwords = [encoding.decode([token]) for token in tokens]\n",
        "    print(f\"Original text: {text}\")\n",
        "    print(f\"\\nTokens: {tokens}\")\n",
        "    print(f\"\\nSubwords: {subwords}\")\n",
        "    print(\"\\nToken to subword mapping:\")\n",
        "    for token, subword in zip(tokens, subwords):\n",
        "        print(f\"Token: {token}, Subword: {subword.encode('utf-8')}\")\n",
        "\n",
        "from_text_to_tokens(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8Q0HXMRktqQ",
        "outputId": "d8dc1a48-fa6f-469f-e4f3-122c2e356ed6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: def hello_world(): print('Hello, world! 🌍') # Bonjour, 世界! Hola, mundo! 1 + 1 = 2, π ≈ 3.14159, e^(i*π) + 1 = 0.\n",
            "\n",
            "Tokens: [755, 24748, 32892, 4658, 1194, 493, 9906, 11, 1917, 0, 11410, 234, 235, 873, 674, 13789, 30362, 11, 220, 3574, 244, 98220, 0, 473, 8083, 11, 29452, 0, 220, 16, 489, 220, 16, 284, 220, 17, 11, 52845, 21784, 230, 220, 18, 13, 9335, 2946, 11, 384, 13571, 72, 9, 49345, 8, 489, 220, 16, 284, 220, 15, 13]\n",
            "\n",
            "Subwords: ['def', ' hello', '_world', '():', ' print', \"('\", 'Hello', ',', ' world', '!', ' �', '�', '�', \"')\", ' #', ' Bon', 'jour', ',', ' ', '�', '�', '界', '!', ' H', 'ola', ',', ' mundo', '!', ' ', '1', ' +', ' ', '1', ' =', ' ', '2', ',', ' π', ' �', '�', ' ', '3', '.', '141', '59', ',', ' e', '^(', 'i', '*', 'π', ')', ' +', ' ', '1', ' =', ' ', '0', '.']\n",
            "\n",
            "Token to subword mapping:\n",
            "Token: 755, Subword: b'def'\n",
            "Token: 24748, Subword: b' hello'\n",
            "Token: 32892, Subword: b'_world'\n",
            "Token: 4658, Subword: b'():'\n",
            "Token: 1194, Subword: b' print'\n",
            "Token: 493, Subword: b\"('\"\n",
            "Token: 9906, Subword: b'Hello'\n",
            "Token: 11, Subword: b','\n",
            "Token: 1917, Subword: b' world'\n",
            "Token: 0, Subword: b'!'\n",
            "Token: 11410, Subword: b' \\xef\\xbf\\xbd'\n",
            "Token: 234, Subword: b'\\xef\\xbf\\xbd'\n",
            "Token: 235, Subword: b'\\xef\\xbf\\xbd'\n",
            "Token: 873, Subword: b\"')\"\n",
            "Token: 674, Subword: b' #'\n",
            "Token: 13789, Subword: b' Bon'\n",
            "Token: 30362, Subword: b'jour'\n",
            "Token: 11, Subword: b','\n",
            "Token: 220, Subword: b' '\n",
            "Token: 3574, Subword: b'\\xef\\xbf\\xbd'\n",
            "Token: 244, Subword: b'\\xef\\xbf\\xbd'\n",
            "Token: 98220, Subword: b'\\xe7\\x95\\x8c'\n",
            "Token: 0, Subword: b'!'\n",
            "Token: 473, Subword: b' H'\n",
            "Token: 8083, Subword: b'ola'\n",
            "Token: 11, Subword: b','\n",
            "Token: 29452, Subword: b' mundo'\n",
            "Token: 0, Subword: b'!'\n",
            "Token: 220, Subword: b' '\n",
            "Token: 16, Subword: b'1'\n",
            "Token: 489, Subword: b' +'\n",
            "Token: 220, Subword: b' '\n",
            "Token: 16, Subword: b'1'\n",
            "Token: 284, Subword: b' ='\n",
            "Token: 220, Subword: b' '\n",
            "Token: 17, Subword: b'2'\n",
            "Token: 11, Subword: b','\n",
            "Token: 52845, Subword: b' \\xcf\\x80'\n",
            "Token: 21784, Subword: b' \\xef\\xbf\\xbd'\n",
            "Token: 230, Subword: b'\\xef\\xbf\\xbd'\n",
            "Token: 220, Subword: b' '\n",
            "Token: 18, Subword: b'3'\n",
            "Token: 13, Subword: b'.'\n",
            "Token: 9335, Subword: b'141'\n",
            "Token: 2946, Subword: b'59'\n",
            "Token: 11, Subword: b','\n",
            "Token: 384, Subword: b' e'\n",
            "Token: 13571, Subword: b'^('\n",
            "Token: 72, Subword: b'i'\n",
            "Token: 9, Subword: b'*'\n",
            "Token: 49345, Subword: b'\\xcf\\x80'\n",
            "Token: 8, Subword: b')'\n",
            "Token: 489, Subword: b' +'\n",
            "Token: 220, Subword: b' '\n",
            "Token: 16, Subword: b'1'\n",
            "Token: 284, Subword: b' ='\n",
            "Token: 220, Subword: b' '\n",
            "Token: 15, Subword: b'0'\n",
            "Token: 13, Subword: b'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "more_example_text = \"Harpreet Sahota is writing a book RAG and is so happy you're joining him on the journey!\"\n",
        "from_text_to_tokens(more_example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr7QNNaulJ0H",
        "outputId": "023b1e92-584c-4b83-b22a-8aa0a7c4c00c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: Harpreet Sahota is writing a book RAG and is so happy you're joining him on the journey!\n",
            "\n",
            "Tokens: [27588, 1762, 295, 43059, 6217, 374, 4477, 264, 2363, 432, 1929, 323, 374, 779, 6380, 499, 2351, 18667, 1461, 389, 279, 11879, 0]\n",
            "\n",
            "Subwords: ['Har', 'pre', 'et', ' Sah', 'ota', ' is', ' writing', ' a', ' book', ' R', 'AG', ' and', ' is', ' so', ' happy', ' you', \"'re\", ' joining', ' him', ' on', ' the', ' journey', '!']\n",
            "\n",
            "Token to subword mapping:\n",
            "Token: 27588, Subword: b'Har'\n",
            "Token: 1762, Subword: b'pre'\n",
            "Token: 295, Subword: b'et'\n",
            "Token: 43059, Subword: b' Sah'\n",
            "Token: 6217, Subword: b'ota'\n",
            "Token: 374, Subword: b' is'\n",
            "Token: 4477, Subword: b' writing'\n",
            "Token: 264, Subword: b' a'\n",
            "Token: 2363, Subword: b' book'\n",
            "Token: 432, Subword: b' R'\n",
            "Token: 1929, Subword: b'AG'\n",
            "Token: 323, Subword: b' and'\n",
            "Token: 374, Subword: b' is'\n",
            "Token: 779, Subword: b' so'\n",
            "Token: 6380, Subword: b' happy'\n",
            "Token: 499, Subword: b' you'\n",
            "Token: 2351, Subword: b\"'re\"\n",
            "Token: 18667, Subword: b' joining'\n",
            "Token: 1461, Subword: b' him'\n",
            "Token: 389, Subword: b' on'\n",
            "Token: 279, Subword: b' the'\n",
            "Token: 11879, Subword: b' journey'\n",
            "Token: 0, Subword: b'!'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY= userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "TpAtkyn3CMqY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if you wanna see your original api key\n",
        "#print(OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "9J-PKzVuCR4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "def get_text_embedding(text: str, model: str = \"text-embedding-3-large\") -> list:\n",
        "    \"\"\"\n",
        "    Get the vector representation of the input text using the specified OpenAI embedding model.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be embedded.\n",
        "        model (str, optional): The name of the OpenAI embedding model to use. Defaults to \"text-embedding-3-large\".\n",
        "\n",
        "    Returns:\n",
        "        list: The vector representation of the input text as a list of floats.\n",
        "\n",
        "    Raises:\n",
        "        OpenAIError: If an error occurs during the API call.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Call OpenAI's API to get the embedding for the text\n",
        "        response = openai.Embedding.create(\n",
        "            input=text,\n",
        "            model=model\n",
        "        )\n",
        "        embedding = response['data'][0]['embedding']\n",
        "        return embedding\n",
        "    except openai.OpenAIError as e:\n",
        "        raise e\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fZpncscUxU-D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This string has {num_tokens_from_string(example_text)} tokens\")\n",
        "\n",
        "vector = get_text_embedding(example_text)\n",
        "\n",
        "print(f\"The vector representation of the text has: {len(vector)} elements\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRiipFwQnV9I",
        "outputId": "73ebd619-6b18-43ce-ca8a-899884ce5d08"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This string has 59 tokens\n",
            "The vector representation of the text has: 3072 elements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40ssCpT4p73g",
        "outputId": "13cd9b38-4838-4578-9e49-4bf70f311503"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.022949282079935074,\n",
              " -0.02234981767833233,\n",
              " -0.011378500610589981,\n",
              " 0.02159200608730316,\n",
              " -0.016490908339619637,\n",
              " -0.009919428266584873,\n",
              " 0.03698578104376793,\n",
              " 0.03863713517785072,\n",
              " 0.01703381910920143,\n",
              " 0.007170943543314934]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This string has {num_tokens_from_string(more_example_text)} tokens\")\n",
        "\n",
        "vector = get_text_embedding(more_example_text)\n",
        "\n",
        "print(f\"The vector representation of the text has: {len(vector)} elements\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC0VPZe8DHpP",
        "outputId": "e1fef7ce-03a8-405b-a65d-13eb780cad1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This string has 23 tokens\n",
            "The vector representation of the text has: 3072 elements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "arxiv_chunked_dataset = load_dataset(\"jamescalam/ai-arxiv-chunked\", split=\"train\")\n",
        "\n",
        "sampled_dataset = arxiv_chunked_dataset.shuffle(seed=51).select(range(100)).to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "fd41cde8331b4da8a564fb175961cd1e",
            "cd1bc3878fd04dbe9b366b28b8e8cef3",
            "2d5e496f78be4a8e87eb2184a4cfc5ab",
            "0909d666d6b14e0081d69055dd7d01f3",
            "f7c0f3aea0124ab2b4427fc281cc49da",
            "09d71485cc72471baad7e23a6dd4ed07",
            "30e28c6c189e4b41af564fd0ba389d8f",
            "1c0b199e50434b209d11f3fd87d00fbb",
            "e39f86567f4b4f7ba29703299ce48e15",
            "0681d4966c704f56b9896ba150a0464a",
            "b67ea910dc8e45daaeb266c7c74629c1",
            "d8d9afd7a71f4ab2b49c2826b9d93328",
            "47f9179b163648d4980fb7e2933c815c",
            "1fd82cb66f7447beadb914b9b4601a81",
            "ee3ce872a1f04044bf92d3f4ede07156",
            "29cceb6785474dc192c408901df97300",
            "ec3482d47c174f5d8fc1a8d345d8d1f9",
            "0aedeebc6f26469891e5820d61e5a099",
            "e542a2395e464c40a4e22c6d865e0609",
            "e66e7d8a711d45f9a1830dcbcdddff67",
            "af2006fb8c374ee883d04eee48ead8be",
            "dabbce0532c8449c9d058674c33d4f3f"
          ]
        },
        "id": "w5eqw72lDSqX",
        "outputId": "42f7f196-196d-44da-90b9-1bbffc75c70a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/153M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd41cde8331b4da8a564fb175961cd1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/41584 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8d9afd7a71f4ab2b49c2826b9d93328"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4CQ8J1OEDGg",
        "outputId": "b42da295-ee80-4de4-e060-349aebd0f297"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doi': '2210.02406',\n",
              " 'chunk-id': '4',\n",
              " 'chunk': 'Figure 1: While standard approaches only provide labeled examples (shown as a grey input box\\nwith green label box), Chain-of-Thought prompting also describes the reasoning steps to arrive at\\nthe answer for every example in the prompt. Decomposed Prompting, on the other hand, uses the\\ndecomposer prompt to only describe the procedure to solve the complex tasks using certain subtasks. Each sub-task, indicated here with A, B and C is handled by sub-task speciﬁc handlers which\\ncan vary from a standard prompt (sub-task A), a further decomposed prompt (sub-task B) or a\\nsymbolic function such as retrieval (sub-task C)\\nprompt only describes a sequence of sub-tasks (A, B, and C) needed to solve the complex tasks, indicated with the dashed lines. Each sub-task is then delegated to the corresponding sub-task handler\\nshown on the right.\\nUsing a software engineering analogy, the decomposer deﬁnes the top-level program for the complex task using interfaces to simpler, sub-task functions. The sub-task handlers serve as modular,\\ndebuggable, and upgradable implementations of these simpler functions, akin to a software library.\\nIf a particular sub-task handler, say the one for identifying the kthletter or retrieving a document,',\n",
              " 'id': '2210.02406',\n",
              " 'title': 'Decomposed Prompting: A Modular Approach for Solving Complex Tasks',\n",
              " 'summary': 'Few-shot prompting is a surprisingly powerful way to use Large Language\\nModels (LLMs) to solve various tasks. However, this approach struggles as the\\ntask complexity increases or when the individual reasoning steps of the task\\nthemselves are hard to learn, especially when embedded in more complex tasks.\\nTo address this, we propose Decomposed Prompting, a new approach to solve\\ncomplex tasks by decomposing them (via prompting) into simpler sub-tasks that\\ncan be delegated to a library of prompting-based LLMs dedicated to these\\nsub-tasks. This modular structure allows each prompt to be optimized for its\\nspecific sub-task, further decomposed if necessary, and even easily replaced\\nwith more effective prompts, trained models, or symbolic functions if desired.\\nWe show that the flexibility and modularity of Decomposed Prompting allows it\\nto outperform prior work on few-shot prompting using GPT3. On symbolic\\nreasoning tasks, we can further decompose sub-tasks that are hard for LLMs into\\neven simpler solvable sub-tasks. When the complexity comes from the input\\nlength, we can recursively decompose the task into the same task but with\\nsmaller inputs. We also evaluate our approach on textual multi-step reasoning\\ntasks: on long-context multi-hop QA task, we can more effectively teach the\\nsub-tasks via our separate sub-tasks prompts; and on open-domain multi-hop QA,\\nwe can incorporate a symbolic information retrieval within our decomposition\\nframework, leading to improved performance on both tasks. Datasets, Code and\\nPrompts available at https://github.com/allenai/DecomP.',\n",
              " 'source': 'http://arxiv.org/pdf/2210.02406',\n",
              " 'authors': ['Tushar Khot',\n",
              "  'Harsh Trivedi',\n",
              "  'Matthew Finlayson',\n",
              "  'Yao Fu',\n",
              "  'Kyle Richardson',\n",
              "  'Peter Clark',\n",
              "  'Ashish Sabharwal'],\n",
              " 'categories': ['cs.CL'],\n",
              " 'comment': \"ICLR'23 Camera Ready\",\n",
              " 'journal_ref': None,\n",
              " 'primary_category': 'cs.CL',\n",
              " 'published': '20221005',\n",
              " 'updated': '20230411',\n",
              " 'references': [{'id': '2210.03350'},\n",
              "  {'id': '2207.10342'},\n",
              "  {'id': '2205.12255'},\n",
              "  {'id': '2210.02406'},\n",
              "  {'id': '2204.02311'},\n",
              "  {'id': '2110.14168'},\n",
              "  {'id': '2204.10019'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "QDRANT_API_KEY=userdata.get('QDRANT_API_KEY')\n",
        "QDRANT_URL=userdata.get('QDRANT_URL')"
      ],
      "metadata": {
        "id": "16-ft5EqFG1l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(QDRANT_API_KEY)\n",
        "#print(QDRANT_URL)"
      ],
      "metadata": {
        "id": "T9Z6GhrWFJHM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dani\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams\n",
        "\n",
        "from qdrant_client import QdrantClient\n",
        "q_client = QdrantClient(\n",
        "    url=QDRANT_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        ")\n",
        "\n",
        "\n",
        "# Create a collection\n",
        "q_client.create_collection(\n",
        "    collection_name=\"arxiv_chunks\",\n",
        "    vectors_config={\n",
        "        \"chunk\": VectorParams(size=3072, distance=Distance.COSINE),\n",
        "        \"summary\": VectorParams(size=3072, distance=Distance.COSINE),\n",
        "    }\n",
        ")\n",
        "print(\"Collection 'arxiv_chunks' created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt1LXhJyFHen",
        "outputId": "9685ba12-807d-41ad-c6f3-627afd24274d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'arxiv_chunks' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import uuid\n",
        "from qdrant_client.http.models import UpdateStatus\n",
        "from qdrant_client.models import PointStruct\n",
        "\n",
        "def add_data_to_collection(data: List[dict], qdrant_client: QdrantClient = q_client, collection_name: str = \"arxiv_chunks\"):\n",
        "    \"\"\"\n",
        "    Inserts data into the Qdrant vector database.\n",
        "\n",
        "    Args:\n",
        "        data (List[dict]): A list of dictionaries containing the data to be inserted.\n",
        "            Each dictionary should have the following keys:\n",
        "            - 'summary': The summary text to be converted into a vector embedding.\n",
        "            - 'chunk': The chunk text to be converted into a vector embedding.\n",
        "            - 'title': The title of the document.\n",
        "            - 'source': The source URL of the document.\n",
        "            - 'authors': A list of authors of the document.\n",
        "        qdrant_client (QdrantClient): An instance of the QdrantClient. Defaults to qdrant_client.\n",
        "        collection_name (str): The name of the collection in which to insert the data. Defaults to \"arxiv_chunks\".\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # instantiate an empty list for the points\n",
        "    points = []\n",
        "\n",
        "    # get the relevent data from the input dictionary\n",
        "    for item in data:\n",
        "        text_id = str(uuid.uuid4())\n",
        "        summary = item.get(\"summary\")\n",
        "        chunk = item.get(\"chunk\")\n",
        "        title = item.get(\"title\")\n",
        "        source = item.get(\"source\")\n",
        "        authors = item.get(\"authors\")\n",
        "\n",
        "        # get the vector embeddings for the summary and chunk\n",
        "        summary_vector = get_text_embedding(summary)\n",
        "        chunk_vector = get_text_embedding(chunk)\n",
        "\n",
        "        # create a dictionary with the vector embeddings\n",
        "        vector_dict = {\"summary\": summary_vector, \"chunk\": chunk_vector}\n",
        "\n",
        "        # create a dictionary with the payload data\n",
        "        payload = {\n",
        "            \"text_id\":text_id,\n",
        "            \"title\": title,\n",
        "            \"source\": source,\n",
        "            \"authors\": authors,\n",
        "            \"chunk\": chunk,\n",
        "            \"summary\": summary,\n",
        "            }\n",
        "\n",
        "        # create a PointStruct object and append it to the list of points\n",
        "        point = PointStruct(id=text_id, vector=vector_dict, payload=payload)\n",
        "        points.append(point)\n",
        "\n",
        "    operation_info = qdrant_client.upsert(\n",
        "        collection_name=collection_name,\n",
        "        wait=True,\n",
        "        points=points)\n",
        "\n",
        "    if operation_info.status == UpdateStatus.COMPLETED:\n",
        "        print(\"Data inserted successfully!\")\n",
        "    else:\n",
        "        print(\"Failed to insert data\")"
      ],
      "metadata": {
        "id": "SEkHKtXiFVr3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_data_to_collection(sampled_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyCuBEXeHkKQ",
        "outputId": "4a59d511-dc9a-4454-ac0d-14fa046afb2b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inserted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "q_client.get_collections()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JwnBGkTH7mJ",
        "outputId": "2ca12493-56a5-41c9-a04d-bc58d24c0c37"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CollectionsResponse(collections=[CollectionDescription(name='arxiv_chunks')])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_collection = q_client.get_collection(\"arxiv_chunks\")\n",
        "\n",
        "print(f\"This collection has {arxiv_collection.points_count} points\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-ilGdvsIXX8",
        "outputId": "875e7f77-a1fe-4a6e-8292-33256a41db7d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This collection has 100 points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of items in dataset:\", len(sampled_dataset))\n",
        "\n",
        "# Check for duplicates in titles or text chunks\n",
        "unique_titles = set([item[\"title\"] for item in sampled_dataset])\n",
        "print(\"Unique titles:\", len(unique_titles))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y377RUqfJX1A",
        "outputId": "c3f25908-109c-4a2d-c3c5-b5a4391169f8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items in dataset: 100\n",
            "Unique titles: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_client.close()"
      ],
      "metadata": {
        "id": "z2nl3Ln_IwCv"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}